[
  {
    "id": 1757592588273,
    "question": "Explain the concept of partitioning in distributed computing and its significance",
    "company": "Seed Question",
    "difficulty": "medium",
    "topic": "System Design",
    "solution": "```markdown\nPartitioning means splitting a large dataset into smaller chunks (partitions) distributed across multiple nodes so they can be processed in parallel. It improves scalability, query performance, and fault tolerance, since only the relevant partitions are scanned or recomputed. For example, partitioning a transactions table by date ensures queries only touch the needed time range instead of the whole dataset.\n```",
    "submittedBy": "dorianganessa",
    "submittedAt": "2025-09-11T12:09:48.273Z",
    "issueNumber": 6,
    "reviewedAt": "2025-09-11T12:11:07.097Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1757595202697,
    "question": "What's the difference between OLTP and OLAP databases?",
    "company": "Seed Question",
    "difficulty": "easy",
    "topic": "Data Modeling",
    "solution": "```markdown\nOLTP (Online Transaction Processing):\n- Designed for real-time transaction processing\n- Handles high volume of short, simple transactions\n- Optimized for INSERT, UPDATE, DELETE operations\n- Supports concurrent users\n- Examples: Banking systems, e-commerce platforms\n\nOLAP (Online Analytical Processing):\n- Designed for complex analytical queries\n- Handles large volumes of historical data\n- Optimized for SELECT operations and aggregations\n- Used for reporting and data analysis\n- Examples: Data warehouses, business intelligence tools\n\nKey differences:\n- OLTP focuses on transaction speed, OLAP focuses on query complexity\n- OLTP uses normalized schemas, OLAP often uses denormalized/star schemas\n- OLTP has frequent updates, OLAP has infrequent updates (batch loads)\n```",
    "submittedBy": "dorianganessa",
    "submittedAt": "2025-09-11T12:53:22.697Z",
    "issueNumber": 13,
    "reviewedAt": "2025-09-11T12:53:50.025Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1757859334674,
    "question": "You’re designing a data pipeline that ingests semi-structured JSON from a Kafka topic into Snowflake. The data contains nested arrays and optional fields. Downstream consumers require both raw access (for data scientists) and flattened, business-ready tables (for analysts).  How would you:  Ingest and store this data so that schema evolution (e.g., new fields appearing, data types changing) is handled gracefully?  Build transformations that generate flattened tables without breaking when upstream fields are missing, renamed, or nested deeper than expected?  Ensure performance and cost efficiency, given that the pipeline must scale from 1M to 100M daily events?",
    "company": "Seed Question",
    "difficulty": "hard",
    "topic": "System Design",
    "solution": "```markdown\n1) Ingestion & storage with graceful schema evolution\n\nEvent contracts + registry: Keep producers on Avro/Protobuf with a Schema Registry (e.g., Confluent) and BACKWARD or FULL compatibility. Each record carries a schema_id so we can resolve the writer schema used at publish time.\n\nLanding pattern:\n\nRaw (immutable) “bronze” table in Snowflake with a VARIANT column for the full payload + ingestion metadata (_ingested_at, _topic, _offset, _partition, _key, _schema_id, _source_version).\n\nIngest via Snowflake Kafka Connector or Snowpipe Streaming (for low-latency/cost). If producers insist on JSON, use a JSON FILE FORMAT and keep the entire object in VARIANT.\n\nPartitioning strategy: Physically organize by a reliable event_time (not ingestion time) where possible; add a clustering key on (to_date(event_time), customer_id) to improve pruning.\n\nWhy this handles evolution: New/optional fields simply appear in the VARIANT; old queries don’t break. We never mutate bronze—only append, so we can replay/backfill under new logic anytime.\n\n2) Transformations that don’t break when structure changes\n\nLayered modeling (bronze → silver → gold):\n\nSilver: Normalize and de-duplicate with idempotent MERGE keyed by a stable event key (event_id + optional source checksum). Use TRY_ functions so missing/changed types don’t fail:\n\nTRY_TO_TIMESTAMP(payload:ts) / COALESCE for fallbacks\n\npayload:\"field\"::variant guarded by IFF(HAS_KEY(payload,'field'), ..., NULL)\n\nRobust flattening: Use LATERAL FLATTEN for arrays with ordinal + path columns, and SAFE casts (TRY_TO_NUMBER, TRY_TO_BOOLEAN). For deeply nested surprises, prefer dot-path access with NULL tolerance rather than hard assumptions.\n\nField renames / path drift: Maintain a small path mapping table (e.g., field_name → json_path(s)) and resolve with COALESCE(payload:path_v3, payload:path_v2, payload:path_v1). This centralizes rename logic so SQL and dbt models don’t whack-a-mole.\n\nContract checks: Add dbt tests (or Great Expectations) for minimal contracts: required keys present, enums valid, cardinalities sane. Fail the silver job (not bronze) with clear errors; bronze still ingests.\n\nMaterialization:\n\nUse dbt incremental models or Snowflake Dynamic Tables for declarative, dependency-aware refresh. Pick lag targets (e.g., 5–10 min for near-real-time marts; hourly/daily for heavy marts).\n\nFor wide denormalized “gold”, keep joins deterministic and avoid exploding rows by pre-aggregating array metrics in silver (e.g., item counts, top-N) to reduce flatten cost.\n\n3) Performance & cost (scaling 1M → 100M events/day)\n\nRight ingestion path: Prefer Snowpipe Streaming (lower latency, fewer staged files) or Kafka Connector with sensible batch sizes. If landing files, target 64–256MB compressed objects to optimize micro-partitions.\n\nWarehouse tuning:\n\nSeparate compute pools: small, autosuspend for ELT control queries; medium/large for heavy transforms; a dedicated pool for ad-hoc data science.\n\nEnable auto-suspend/auto-resume and use multi-cluster only when concurrency actually demands it.\n\nUse Query Acceleration only for spiky/complex workloads after other optimizations.\n\nPruning & clustering: Keep event_date in a top-level column for pruning. Automatic Clustering (or periodic reclustering) on (event_date, customer_id) minimizes scan cost as volume grows.\n\nAvoid unnecessary explosion: Flatten late and locally. For analytics that need only aggregates, aggregate in silver first; don’t fully explode giant arrays just to later re-aggregate.\n\nStorage hygiene: Retain bronze indefinitely (cheap + valuable for reprocessing), but time-travel and fail-safe windows on silver/gold can be shorter. Compress/trim verbose free-text.\n\nObservability & SLAs: Track end-to-end lag, row counts, schema_id distribution, error rates, and cost per 1K events. Alert on drifts (e.g., sudden surge of NULL in required business fields).\n```",
    "submittedBy": "dorianganessa",
    "submittedAt": "2025-09-14T14:15:34.674Z",
    "issueNumber": 15,
    "reviewedAt": "2025-09-14T14:16:30.419Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1759695358999,
    "question": "How do you preserve the history of dimensional data?",
    "company": "Prima Assicurazioni",
    "difficulty": "medium",
    "topic": "Data Modeling",
    "solution": "```markdown\nTalk about slowly changing dimensions, the difference between the different types, when to use one over the other and why\n```",
    "submittedBy": "dorianganessa",
    "submittedAt": "2025-10-05T20:15:58.999Z",
    "issueNumber": 17,
    "reviewedAt": "2025-10-05T20:16:50.586Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1759745962593,
    "question": "How would you build a reliable data pipeline?",
    "company": "Didomi",
    "difficulty": "medium",
    "topic": "System Design",
    "solution": "```markdown\nTalk about data quality, WAP pattern, idempotency, alerts and monitoring + backfills\n```",
    "submittedBy": "dorianganessa",
    "submittedAt": "2025-10-06T10:19:22.593Z",
    "issueNumber": 19,
    "reviewedAt": "2025-10-06T10:20:57.301Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765490640497,
    "question": "Do you know what a strategy pattern is?",
    "company": "Prima",
    "difficulty": "easy",
    "topic": "Other",
    "solution": "```markdown\n\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-11T22:04:00.497Z",
    "issueNumber": 21,
    "reviewedAt": "2025-12-12T10:12:03.587Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765490873989,
    "question": "Do you know about the composite pattern?",
    "company": "Prima",
    "difficulty": "medium",
    "topic": "Other",
    "solution": "```markdown\n\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-11T22:07:53.989Z",
    "issueNumber": 23,
    "reviewedAt": "2025-12-12T10:15:30.888Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765490958516,
    "question": "Do you know what a Medallion architecture is and have you ever used it in past experiences?",
    "company": "Prima",
    "difficulty": "easy",
    "topic": "Data Modeling",
    "solution": "```markdown\n\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-11T22:09:18.516Z",
    "issueNumber": 25,
    "reviewedAt": "2025-12-12T10:16:07.640Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765491008914,
    "question": "Do you know what Slowly Changing Dimensions are and what is type 4?",
    "company": "Prima",
    "difficulty": "medium",
    "topic": "Data Modeling",
    "solution": "```markdown\n\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-11T22:10:08.915Z",
    "issueNumber": 27,
    "reviewedAt": "2025-12-12T13:28:32.144Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765491150169,
    "question": "Do you know what a Singleton pattern is? (DE II position)",
    "company": "Agile Lab",
    "difficulty": "easy",
    "topic": "Data Structures & Algorithms",
    "solution": "```markdown\n\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-11T22:12:30.169Z",
    "issueNumber": 29,
    "reviewedAt": "2025-12-12T13:29:05.821Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765491243051,
    "question": "Do you know the difference between Interpreted vs compiled languages? (DE II)",
    "company": "Agile Lab",
    "difficulty": "easy",
    "topic": "Other",
    "solution": "```markdown\n\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-11T22:14:03.051Z",
    "issueNumber": 31,
    "reviewedAt": "2025-12-12T13:30:28.766Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765491525464,
    "question": "How would you improve a Pipeline performance? (DE II)",
    "company": "Agile Lab",
    "difficulty": "hard",
    "topic": "Performance Optimisation",
    "solution": "```markdown\nI tried to tackle this question dividing in two case:\n- Using dbt/sql. In this case I tried to talk about analyzing Joins, Order of execution between Joins, Where conditions and so on, possible use of CTE and window functions. Data cleaning and filtering, imputation and so on.\n- Using python. Understading if we need pandas, polars (parallelised) or Spark. And for each case again talked about filtering, imputing, loops/buidler patterns, memory management in case of distributed system. Partitioning and classical concepts.\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-11T22:18:45.464Z",
    "issueNumber": 35,
    "reviewedAt": "2025-12-12T14:03:27.417Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765491303857,
    "question": "Can you name what are the SOLID Principles and quickly explain them? (DE II)",
    "company": "Agile Lab",
    "difficulty": "easy",
    "topic": "Other",
    "solution": "```markdown\n\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-11T22:15:03.857Z",
    "issueNumber": 33,
    "reviewedAt": "2025-12-12T14:07:01.442Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765491843812,
    "question": "Do you know what a Lambda function is? (Python)",
    "company": "Agile Lab",
    "difficulty": "easy",
    "topic": "Live Coding",
    "solution": "```markdown\n\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-11T22:24:03.812Z",
    "issueNumber": 39,
    "reviewedAt": "2025-12-12T14:07:22.153Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765492535053,
    "question": "Do you know what a Parquet file is and where it is being used?",
    "company": "Agile Lab",
    "difficulty": "easy",
    "topic": "Data Structures & Algorithms",
    "solution": "```markdown\n\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-11T22:35:35.053Z",
    "issueNumber": 43,
    "reviewedAt": "2025-12-12T14:07:53.023Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765491640453,
    "question": "What kind of CI would guarantee and check for good software quality? (DE II)",
    "company": "Agile Lab",
    "difficulty": "medium",
    "topic": "Other",
    "solution": "```markdown\nTried to talk of usual CI workflows\n- linter\n- type checker\n- formatter\n- unit tester\n- environment set up\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-11T22:20:40.453Z",
    "issueNumber": 37,
    "reviewedAt": "2025-12-12T14:08:38.028Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765500970457,
    "question": "What would you change in the hiring process?",
    "company": "Prima",
    "difficulty": "medium",
    "topic": "Behavioral",
    "solution": "```markdown\nThis question looks innocent but I thought actually probes a lot of about you.\nI think they look for:\n- Critical Thinking & Awareness: Can you identify inefficiencies, gaps, or areas for improvement?\n- Problem-Solving & Constructive Feedback: they want to see if you can offer solutions and how you give constructive feedbacks\n- Empathy: they’re assessing whether you’re empathetic toward candidates. Can you see how the process feels from the other side?\n- Alignment with Company Values / Hiring Philosophy:your answer can reveal if your approach to hiring aligns with theirs. Do you value skill, culture fit, diversity, efficiency...?\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-12T00:56:10.457Z",
    "issueNumber": 63,
    "reviewedAt": "2025-12-12T14:12:55.684Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765500665023,
    "question": "What would you change in your current work environment?",
    "company": "Prima",
    "difficulty": "medium",
    "topic": "Behavioral",
    "solution": "```markdown\nWatch out on this one. They do not want you to hear bad things about your previous company, colleagues or manager. They do not want to be next on the list of people you shit on. They want to test you maturity and ability to really sense the environment. For me what worked was referring to my small company. Since I was reporting directly to the CTO I missed having protection and not being exposed to project management, politics and so on. So I just said I would like to have engineering managers helping me focus on my work and grow as engineer.\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-12T00:51:05.023Z",
    "issueNumber": 61,
    "reviewedAt": "2025-12-12T14:13:51.220Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765500279545,
    "question": "How do you manage priorities at work?",
    "company": "Prima",
    "difficulty": "medium",
    "topic": "Behavioral",
    "solution": "```markdown\nThis was a very general one. I tried to answer with more details possible and a lot of reference to my daily work:\n- set priorities doing team agile session\n- align with business needs\n- align with colleagues and manager\n- first small quick task \n- brake down larger task/projects\n- of course balance deadlines\n- continues feedback from manager and company OKRs\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-12T00:44:39.545Z",
    "issueNumber": 57,
    "reviewedAt": "2025-12-12T14:15:17.863Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765500100701,
    "question": "How did you manage difficult situations / stakeholder interactions?",
    "company": "Prima",
    "difficulty": "medium",
    "topic": "Behavioral",
    "solution": "```markdown\n\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-12T00:41:40.701Z",
    "issueNumber": 55,
    "reviewedAt": "2025-12-12T14:15:44.181Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765500035445,
    "question": "How do you react to negative feedbacks?",
    "company": "Prima",
    "difficulty": "medium",
    "topic": "Behavioral",
    "solution": "```markdown\n\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-12T00:40:35.445Z",
    "issueNumber": 53,
    "reviewedAt": "2025-12-12T14:16:12.072Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765499962534,
    "question": "how do you give negative feedbacks? Can you make an example from your past experiences?",
    "company": "Prima",
    "difficulty": "medium",
    "topic": "Behavioral",
    "solution": "```markdown\n\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-12T00:39:22.534Z",
    "issueNumber": 51,
    "reviewedAt": "2025-12-12T14:16:35.812Z",
    "reviewedBy": "dorianganessa"
  },
  {
    "id": 1765492794259,
    "question": "What are source and model in dbt",
    "company": "Jet HR",
    "difficulty": "easy",
    "topic": "Other",
    "solution": "```markdown\n\n```",
    "submittedBy": "nicdelillo",
    "submittedAt": "2025-12-11T22:39:54.259Z",
    "issueNumber": 49,
    "reviewedAt": "2025-12-12T14:17:08.128Z",
    "reviewedBy": "dorianganessa"
  }
]